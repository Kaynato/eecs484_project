{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Quick and Compact Bezier Curve Detection with Fast Meta CNNs\n",
    "\"\"\"\n",
    "\n",
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorpack as tp\n",
    "from tensorpack.tfutils.summary import add_moving_summary\n",
    "from tensorpack.tfutils.scope_utils import auto_reuse_variable_scope\n",
    "import tensorpack.tfutils.symbolic_functions as symbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DIMS = (64, 64)\n",
    "BATCH = 100\n",
    "EX_PER_FILE = 100\n",
    "\n",
    "NET_OPTION = 'fwb'\n",
    "USE_IDYX = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SAVE_DIR = './data/'\n",
    "MASK_DIR = os.path.join(SAVE_DIR, 'masks')\n",
    "PARAM_DIR = os.path.join(SAVE_DIR, 'params')\n",
    "WIDTH_DIR = os.path.join(SAVE_DIR, 'widths')\n",
    "\n",
    "# Special dataflow\n",
    "class LineDataFlow(tp.RNGDataFlow):\n",
    "    \n",
    "    def __init__(self, filenames, do_shuffle):\n",
    "        self.filenames = filenames\n",
    "        self.do_shuffle = do_shuffle\n",
    "        \n",
    "    def size(self):\n",
    "        return len(self.filenames) * EX_PER_FILE\n",
    "    \n",
    "    def get_data(self):\n",
    "        for name in self.filenames:\n",
    "            masks = np.load(os.path.join(MASK_DIR, name))\n",
    "            params = np.load(os.path.join(PARAM_DIR, name))\n",
    "            widths = np.load(os.path.join(WIDTH_DIR, name))\n",
    "            \n",
    "            idx = np.r_[:masks.shape[0]]\n",
    "            if self.do_shuffle:\n",
    "                np.random.shuffle(idx)\n",
    "            for i in idx:\n",
    "                yield [masks[i], params[i], widths[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_files = ['{:02}.npy'.format(i) for i in range(100)]\n",
    "filesets = {\n",
    "    'train': all_files[:70],\n",
    "    'val': all_files[70:80],\n",
    "    'test': all_files[80:]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(fileset, group):\n",
    "    ds = LineDataFlow(fileset, do_shuffle=group == 'train')\n",
    "    ds = tp.BatchData(ds, BATCH)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# base feature count width\n",
    "NF = 16\n",
    "\n",
    "INITS = {\n",
    "    'TNC': tf.truncated_normal_initializer(stddev=0.02),\n",
    "    'VSI': tf.contrib.layers.variance_scaling_initializer(factor=1.0, mode='FAN_AVG', uniform=True)\n",
    "}\n",
    "\n",
    "def visualize_conv_activations(activation, name):\n",
    "    \"\"\"Visualize activations for convolution layers.\n",
    "\n",
    "    Remarks:\n",
    "        This tries to place all activations into a square.\n",
    "\n",
    "    Args:\n",
    "        activation: tensor with the activation [B,H,W,C]\n",
    "        name: label for tensorboard\n",
    "\n",
    "    Returns:\n",
    "        image of almost all activations\n",
    "    \"\"\"\n",
    "    import math\n",
    "    with tf.name_scope('visualize_act_' + name):\n",
    "        _, h, w, c = activation.get_shape().as_list()\n",
    "        rows = []\n",
    "        c_per_row = int(math.sqrt(c))\n",
    "        for y in range(0, c - c_per_row, c_per_row):\n",
    "            row = activation[:, :, :, y:y + c_per_row]  # [?, H, W, 32] --> [?, H, W, 5]\n",
    "            cols = tf.unstack(row, axis=3)              # [?, H, W, 5] --> 5 * [?, H, W]\n",
    "            row = tf.concat(cols, 1)\n",
    "            rows.append(row)\n",
    "\n",
    "        viz = tf.concat(rows, 2)\n",
    "    tf.summary.image('visualize_act_' + name, tf.expand_dims(viz, -1))\n",
    "\n",
    "def coord_to_points(arr, coords, coords_, idy, idx):\n",
    "    # coord quadruplets only\n",
    "    arr_B = arr * 255.0\n",
    "    # Blue = mask\n",
    "    \n",
    "    with tf.name_scope('viz_points'):\n",
    "        # Label coords (bigger) - green\n",
    "        arr_G = tf.zeros_like(arr)\n",
    "        for coord in tf.split(coords, 4, axis=1): # -> (B, yx)\n",
    "            coord = tf.reshape(coord, [-1, 1, 1, 2])\n",
    "            dysq = tf.square(idy - coord[..., 0] * DIMS[0])\n",
    "            dxsq = tf.square(idx - coord[..., 1] * DIMS[1])\n",
    "            raster = tf.less_equal(dysq + dxsq, 2.0)\n",
    "            raster = tf.expand_dims(raster, axis=3)\n",
    "            arr_G += tf.cast(raster, tf.float32)\n",
    "            \n",
    "        # Guessed coords (smaller) - red\n",
    "        arr_R = tf.zeros_like(arr)\n",
    "        for coord in tf.split(coords_, 4, axis=1): # -> (B, yx)\n",
    "            coord = tf.reshape(coord, [-1, 1, 1, 2])\n",
    "            dysq = tf.square(idy - coord[..., 0] * DIMS[0])\n",
    "            dxsq = tf.square(idx - coord[..., 1] * DIMS[1])\n",
    "            raster = tf.less_equal(dysq + dxsq, 1.5)\n",
    "            raster = tf.expand_dims(raster, axis=3)\n",
    "            arr_R += tf.cast(raster, tf.float32)\n",
    "    \n",
    "        return tf.concat([arr_R * 255, arr_G * 255, arr_B], axis=3)\n",
    "\n",
    "class Model(tp.ModelDesc):\n",
    "    \n",
    "    def _get_inputs(self):\n",
    "        return [tp.InputDesc(tf.float32, (None,) + DIMS, 'mask'),\n",
    "                tp.InputDesc(tf.float32, (None, 4, 2), 'param'),\n",
    "                tp.InputDesc(tf.float32, (None, 1), 'width')\n",
    "                ]\n",
    "\n",
    "    def networkVGG(self, x, idy, idx):\n",
    "        \"\"\"\n",
    "        VGG Net. Baseline A.\n",
    "        \"\"\"\n",
    "        with tp.argscope(tp.Conv2D, kernel_shape=3, stride=1, nl=tf.nn.elu):\n",
    "            c0 = tp.Conv2D('conv0', x, NF)\n",
    "            \n",
    "            if USE_IDYX:\n",
    "                l = tf.concat([c0 * idy / DIMS[0], c0 * idx / DIMS[1]], axis=3)\n",
    "            \n",
    "            p0 = tp.MaxPooling('pool0', c0, 2) # -> 32x\n",
    "            c1 = tp.Conv2D('conv1', p0, NF * 2)\n",
    "            c2 = tp.Conv2D('conv2', c1, NF * 4)\n",
    "            p1 = tp.MaxPooling('pool1', c2, 2) # -> 16x\n",
    "            c3 = tp.Conv2D('conv3', p1, NF * 4)\n",
    "            c4 = tp.Conv2D('conv4', c3, NF * 8)\n",
    "            p2 = tp.MaxPooling('pool2', c4, 2) # -> 8x\n",
    "            f1 = tp.FullyConnected('fc0', p2, 512)\n",
    "            l  = tp.Dropout('drop', f1, 0.5)\n",
    "            \n",
    "            # Eh, dims are symmetric anyway\n",
    "            param = tp.FullyConnected('fc_param', l, 8, nl=tf.identity)\n",
    "            param = tf.reshape(param, [-1, 4, 2])\n",
    "            \n",
    "            width = tp.FullyConnected('fc_width', l, 1, nl=tf.identity)\n",
    "\n",
    "            visualize_conv_activations(c0, 'c0')\n",
    "            visualize_conv_activations(c2, 'c2')\n",
    "            visualize_conv_activations(c4, 'c4')\n",
    "            \n",
    "        return param, width\n",
    "    \n",
    "    def networkSeq1(self, x, idy, idx):\n",
    "        \"\"\"\n",
    "        Sequential network with factorized filters.\n",
    "        Get outer points first, then inner points.\n",
    "        \"\"\"\n",
    "        with tp.argscope(tp.Conv2D, kernel_shape=3, stride=1, nl=tf.nn.elu):\n",
    "            # Broad filter across first\n",
    "            c0y = tp.Conv2D('conv0y',   x, NF, kernel_shape=[7, 1])\n",
    "            c0x = tp.Conv2D('conv0x', c0y, NF, kernel_shape=[1, 7])\n",
    "            c1  = tp.Conv2D('conv1',  c0x, NF, kernel_shape=[3, 3])\n",
    "            \n",
    "            if USE_IDYX:\n",
    "                yx = tf.concat([c1, c1 * idy / DIMS[0], c1 * idx / DIMS[1]], axis=3)\n",
    "            \n",
    "            # Outer control points' heatmap\n",
    "            c_outer = tp.Conv2D('conv2o', yx, 4)\n",
    "            outer = tp.GlobalAvgPooling('gap_outer', c_outer) # -> 4\n",
    "            outer = tf.reshape(outer, [-1, 2, 2])\n",
    "            point_1, point_4 = tf.split(outer, 2, axis=1)\n",
    "\n",
    "            # Width\n",
    "            c_width = tp.Conv2D('conv2w', c1, 4)\n",
    "            width = tp.FullyConnected('fc_width', c_width, 1, nl=tf.identity)\n",
    "\n",
    "            # Use outer point heatmap and yx to discover inner points\n",
    "            remix = tf.concat([c_outer, yx], axis=3)\n",
    "            c2 = tp.Conv2D('conv2i', remix, NF * 2)\n",
    "            c3 = tp.Conv2D('conv3', c2, NF * 4)\n",
    "            p2 = tp.AvgPooling('pool2', c3, 2) # -> 32x\n",
    "            c_inner = tp.Conv2D('conv4', p2, NF * 4)\n",
    "            g_inner = tp.GlobalAvgPooling('gap_inner', c_inner) # -> 1 x 4NF\n",
    "            inner = tp.FullyConnected('fc_param', g_inner, 4, nl=tf.identity)\n",
    "            inner = tf.reshape(inner, [-1, 2, 2])\n",
    "            point_2, point_3 = tf.split(inner, 2, axis=1)\n",
    "\n",
    "            param = tf.concat([point_1, point_2, point_3, point_4], axis=1)\n",
    "\n",
    "            visualize_conv_activations(yx, 'yx')\n",
    "            visualize_conv_activations(c2, 'c2')\n",
    "            visualize_conv_activations(c_outer, 'c_outer')\n",
    "            visualize_conv_activations(c_inner, 'c_inner')\n",
    "            visualize_conv_activations(c_width, 'c_width')\n",
    "            \n",
    "        return param, width\n",
    "    \n",
    "    def networkSeq2(self, x, idy, idx):\n",
    "        \"\"\"\n",
    "        Sequential network with factorized filters.\n",
    "        Get outer points first, then inner points.\n",
    "        \"\"\"\n",
    "        with tp.argscope(tp.Conv2D, kernel_shape=3, stride=1, nl=tf.nn.elu):\n",
    "            # Broad filter across first\n",
    "            c0y = tp.Conv2D('conv0y',   x, NF, kernel_shape=[7, 1])\n",
    "            c0x = tp.Conv2D('conv0x', c0y, NF, kernel_shape=[1, 7])\n",
    "            c1  = tp.Conv2D('conv1',  c0x, NF, kernel_shape=[5, 5])\n",
    "            cw  = tp.Conv2D('conv1b',  c1, NF, kernel_shape=[5, 5], nl=tf.sigmoid)\n",
    "            \n",
    "            if USE_IDYX:\n",
    "                yx = tf.concat([c1, cw * idy / DIMS[0], cw * idx / DIMS[1]], axis=3)\n",
    "            \n",
    "            # Outer control points' heatmap\n",
    "            l       = tp.Conv2D('conv2o0', yx, 4 * NF)\n",
    "            l       = tp.Conv2D('conv2o1',  l, 4 * NF)\n",
    "            c_outer = tp.Conv2D('conv2o2',  l, 4, nl=tf.sigmoid)\n",
    "            outer = tp.GlobalAvgPooling('gap_outer', c_outer) # -> 4\n",
    "            outer = tf.reshape(outer, [-1, 2, 2])\n",
    "\n",
    "            # Width\n",
    "            c_width = tp.Conv2D('conv2w', c1, 4)\n",
    "            width = tp.FullyConnected('fc_width', c_width, 1, nl=tf.identity)\n",
    "\n",
    "            # Use outer point heatmap and yx to discover inner points\n",
    "            remix = tf.concat([c_outer, yx], axis=3)\n",
    "            c2 = tp.Conv2D('conv2i', remix, NF * 2)\n",
    "            c3 = tp.Conv2D('conv3', c2, NF * 4)\n",
    "            p2 = tp.AvgPooling('pool2', c3, 2) # -> 32x\n",
    "            c4 = tp.Conv2D('conv4', p2, NF * 4)\n",
    "            c_inner = tp.Conv2D('conv5', c4, NF * 4, nl=tf.sigmoid)\n",
    "            g_inner = tp.GlobalAvgPooling('gap_inner', c_inner) # -> 1 x 4NF\n",
    "            inner = tp.FullyConnected('fc_param', g_inner, 4, nl=tf.identity)\n",
    "            inner = tf.reshape(inner, [-1, 2, 2])\n",
    "\n",
    "            point_1, point_4 = tf.split(outer, 2, axis=1)\n",
    "            point_2, point_3 = tf.split(inner, 2, axis=1)\n",
    "            param = tf.concat([point_1, point_2, point_3, point_4], axis=1)\n",
    "\n",
    "            visualize_conv_activations(cw, 'yx')\n",
    "            visualize_conv_activations(yx, 'yx')\n",
    "            visualize_conv_activations(c2, 'c2')\n",
    "            visualize_conv_activations(c_outer, 'c_outer')\n",
    "            visualize_conv_activations(c_inner, 'c_inner')\n",
    "            visualize_conv_activations(c_width, 'c_width')\n",
    "            \n",
    "        return param, width\n",
    "\n",
    "    def networkFWB(self, x, idy, idx):\n",
    "        \"\"\"\n",
    "        Normal deep feedforward with combinations of indexing and mask in beginning.\n",
    "        \"\"\"\n",
    "        with tp.argscope(tp.Conv2D, kernel_shape=3, stride=1, nl=tf.nn.elu):\n",
    "\n",
    "            # +/- mask * idyx\n",
    "            cyp =  x * idy / DIMS[0]\n",
    "            cym = -x * idy / DIMS[0]\n",
    "            cxp =  x * idx / DIMS[1]\n",
    "            cxm = -x * idx / DIMS[1]\n",
    "            l = tf.concat([cxp, cxm, cyp, cym], axis=3)\n",
    "            c0 = tp.Conv2D('conv0', l, NF * 2, kernel_shape=7)\n",
    "            p0 = tp.AvgPooling('pool0', l, 2) # -> 32x\n",
    "            p0  = tp.Dropout('drop1', p0, 0.9)\n",
    "            c1 = tp.Conv2D('conv1', p0, NF * 2)\n",
    "            c2 = tp.Conv2D('conv2', c1, NF * 4)\n",
    "            p1 = tp.AvgPooling('pool1', c2, 2) # -> 16x\n",
    "            p1  = tp.Dropout('drop1', p1, 0.8)\n",
    "            c3 = tp.Conv2D('conv3', p1, NF * 4)\n",
    "            c4 = tp.Conv2D('conv4', c3, NF * 8)\n",
    "            p2 = tp.AvgPooling('pool2', c4, 2) # -> 8x\n",
    "            p2  = tp.Dropout('drop2', p2, 0.7)\n",
    "            c5 = tp.Conv2D('conv5', p2, NF * 8)\n",
    "            c6 = tp.Conv2D('conv6', c5, NF * 16)\n",
    "            p3 = tp.AvgPooling('pool2', c6, 2) # -> 4x\n",
    "            f1 = tp.FullyConnected('fc0', p3, 256)\n",
    "            l  = tp.Dropout('dropf', f1, 0.5)\n",
    "\n",
    "            param = tp.FullyConnected('fc_param', l, 8, nl=tf.sigmoid) * 1.1\n",
    "            param = tf.reshape(param, [-1, 4, 2]) - 0.05\n",
    "            \n",
    "            width = tp.FullyConnected('fc_width', l, 1, nl=tf.sigmoid) * 2.0\n",
    "\n",
    "            visualize_conv_activations(c0, 'c0')\n",
    "            visualize_conv_activations(c2, 'c2')\n",
    "            visualize_conv_activations(c4, 'c4')\n",
    "            visualize_conv_activations(c6, 'c6')\n",
    "            \n",
    "        return param, width\n",
    "    \n",
    "    def _build_graph(self, inputs):\n",
    "        mask, param, width = inputs\n",
    "        \n",
    "        with tf.name_scope('indexing'):\n",
    "            np_idx = np.c_[:DIMS[0]] + np.zeros((1, DIMS[0]))\n",
    "            np_idx = np_idx[None, ...]\n",
    "            np_idy = np.r_[:DIMS[1]] + np.zeros((DIMS[0], 1))\n",
    "            np_idy = np_idy[None, ...]\n",
    "            idy = tf.convert_to_tensor(np_idy, dtype='float32')\n",
    "            idx = tf.convert_to_tensor(np_idx, dtype='float32')\n",
    "        \n",
    "        # Standardize\n",
    "        with tf.name_scope('prepare_input'):\n",
    "            mask = tf.expand_dims(mask, axis=3)\n",
    "            x = 0.5 - mask\n",
    "            \n",
    "            param = param / DIMS[0]\n",
    "        \n",
    "        net_options = {\n",
    "            'vgg': self.networkVGG,\n",
    "            'seq1': self.networkSeq1,\n",
    "            'seq2': self.networkSeq2,\n",
    "            'fwb': self.networkFWB\n",
    "        }\n",
    "        with tp.argscope([tp.Conv2D], W_init=INITS['VSI']):\n",
    "            with tf.variable_scope('encoder'):\n",
    "                param_, width_ = net_options[NET_OPTION](x,\n",
    "                                                         tf.expand_dims(idy, axis=3),\n",
    "                                                         tf.expand_dims(idx, axis=3))\n",
    "        \n",
    "        with tf.name_scope('outputs'):\n",
    "            param_ = tf.identity(param_, name='params')\n",
    "            width_ = tf.identity(width_, name='widths')\n",
    "            \n",
    "        with tf.name_scope('loss'):\n",
    "            # MSE losses (reduce to 0-1)\n",
    "            p_loss = tf.reduce_mean(tf.square(param_ - param), axis=(1, 2))\n",
    "            tf.summary.histogram(values=p_loss, name='summary-params')\n",
    "            p_loss = tf.reduce_mean(p_loss, name='params')\n",
    "            \n",
    "            w_loss = tf.reduce_mean(tf.square(width_ - width), axis=(1))\n",
    "            tf.summary.histogram(values=w_loss, name='summary-widths')\n",
    "            w_loss = tf.reduce_mean(w_loss, name='widths')\n",
    "            \n",
    "            add_moving_summary(p_loss, w_loss)\n",
    "            cost = p_loss + w_loss\n",
    "            \n",
    "            reg_loss = tf.multiply(1e-5, tp.regularize_cost('fc.*/W', tf.nn.l2_loss),\n",
    "                                   name='regularize_loss')\n",
    "            self.cost = tf.add_n([reg_loss, cost], name='total_cost')\n",
    "            add_moving_summary(self.cost)\n",
    "            \n",
    "        # Expose to circumvent naming / folder issue\n",
    "        p_loss = tf.identity(p_loss, name='loss_params')\n",
    "        \n",
    "        if tp.tfutils.get_current_tower_context().is_training:\n",
    "            tf.summary.image('mask', mask, max_outputs=10)\n",
    "            tf.summary.image('points', coord_to_points(mask, param, param_, idx, idy), max_outputs=10)\n",
    "\n",
    "    def _get_optimizer(self):\n",
    "        lr = symbf.get_scalar_var('learning_rate', 4e-4, summary=True)\n",
    "        return tf.train.AdamOptimizer(lr, beta1=0.5, epsilon=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LOAD = './train_log/linenetFwbVSI3/model-3010'\n",
    "\n",
    "dataflows = {group: get_data(fileset, group) for group, fileset in filesets.items()}\n",
    "\n",
    "tp.logger.set_logger_dir('./train_log/linenetFwbVSI3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "config = tp.TrainConfig(\n",
    "    model=Model(),\n",
    "    dataflow=dataflows['train'],  # the DataFlow instance for training\n",
    "    callbacks=[\n",
    "        tp.ModelSaver(),\n",
    "        tp.MinSaver('loss_params'),\n",
    "        tp.InferenceRunner(\n",
    "            dataflows['val'],\n",
    "            # Calculate both the cost and the error for this DataFlow\n",
    "            [tp.ScalarStats('loss/params'),\n",
    "             tp.ScalarStats('loss/widths')]),\n",
    "    ],\n",
    "    steps_per_epoch=dataflows['train'].size(),\n",
    "    max_epoch=1000,\n",
    ")\n",
    "\n",
    "if LOAD:\n",
    "    config.session_init = tp.SaverRestore(LOAD)\n",
    "\n",
    "tp.QueueInputTrainer(config).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in dataflows['train'].get_data():\n",
    "    q = i\n",
    "    break\n",
    "qm, qp, qw = q\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(qm[2], cmap=plt.cm.gray_r)\n",
    "plt.plot(qp[2, :, 1], qp[2, :, 0], color='red')\n",
    "plt.show()\n",
    "\n",
    "tp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "testconfig = tp.PredictConfig(\n",
    "                  session_init=tp.get_model_loader('./train_log/linenetFwbVSI2/model-16870'),\n",
    "                  model=Model(),\n",
    "                  input_names=['mask'],\n",
    "                  output_names=['outputs/params', 'outputs/widths'])\n",
    "\n",
    "predictor = tp.OfflinePredictor(testconfig)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predictor()\n",
    "\n",
    "for datapoint in dataflows['test'].get_data():\n",
    "    predictor(datapoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
